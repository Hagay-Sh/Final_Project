{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2af74cc",
   "metadata": {},
   "source": [
    "# 🦜🔗 LangChain - Agents & Tools\n",
    "\n",
    "© Advanced Analytics, Amir Ben Haim, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15966a6a",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3bbef",
   "metadata": {},
   "source": [
    "## Agents & Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ee7f",
   "metadata": {},
   "source": [
    "- **Agents**\n",
    "  - Agents - are advanced LLM applications that can decide what steps to take, in what order, **using \"tools\" to accomplish complex tasks**\n",
    "  - Instead of static chains, agents can reason, select tools, and loop until a goal is met — enabling more dynamic, autonomous workflows\n",
    "  - Agent uses tool descriptions to decide when/how to call\n",
    "\n",
    "- **Tools**\n",
    "  - Tools - are Python functions, APIs, or integrations that an agent can use to fetch data, calculate, search, etc\n",
    "  - A <u>toolkit</u> is a bundle of related tools (e.g., file search, web browsing, code execution)\n",
    "  - Tools must be **structured functions** or **OpenAI function calling style**\n",
    "  - LangChain provides many built-in tools (math, search, Python REPL, and more), but you can define your own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386dcbb",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545e89c",
   "metadata": {},
   "source": [
    "## Agents vs. Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d35af",
   "metadata": {},
   "source": [
    "| Chains                     | Agents                                    |\n",
    "|----------------------------|-------------------------------------------|\n",
    "| Fixed sequence of steps    | Dynamic reasoning (choose next action)    |\n",
    "| No decision-making         | Makes decisions at each step              |\n",
    "| Good for linear workflows  | Good for uncertain/multi-step problems    |\n",
    "| Example: Translate, then summarize | Example: Lookup docs, search web, use calculator |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d854d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38265701",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254fd73e",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>API Keys</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d440b",
   "metadata": {},
   "source": [
    "In order to use the OpenAI language model, users are required to generate a token.\n",
    "<br></br>\n",
    "<u>Follow these simple steps to generate a token with openai:</u>\n",
    "- Go to <a href=\"url\">https://platform.openai.com/apps</a>  and signup with your email address or connect your Google Account.\n",
    "- Go to View API Keys on left side of your Personal Account Settings\n",
    "- Select Create new Secret key\n",
    "- The API access to OPENAI is a paid service\n",
    "- You have to set up billing\n",
    "- You don’t need ChatGPT Plus - The API and ChatGPT subscriptions are billed separately\n",
    "<br></br>\n",
    "<p style=\"background-color:Tomato\"> Make sure you read the Pricing information before experimenting</p>\n",
    "<p style=\"background-color:Tomato\">Once you add your API key, make sure to not share it with anyone! The API key should remain private</p>\n",
    "<p style=\"background-color:Tomato\">Use the <code>.env</code> file for you API key</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d306e",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>pip install</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a025c",
   "metadata": {},
   "source": [
    "```powershell\n",
    "pip install langchain langchain-openai langchain-community\n",
    "pip install python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8e8d5",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>API Key Setup</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f7b02",
   "metadata": {},
   "source": [
    "Before using LangChain with OpenAI, set your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6507c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Loads variables from .env\n",
    "\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openai_key[:5])  # Just to check, don't print the full key!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98b51d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe066493",
   "metadata": {},
   "source": [
    "## Example 1: Agent With Calculator Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec303266",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Define a Simple Calculator Tool</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce51a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers and return the result.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44169648",
   "metadata": {},
   "source": [
    "`@tool`\n",
    "<br>\n",
    "\n",
    "- It's a **decorator**\n",
    "\n",
    "- A convenient way to convert a standard Python function into a tool that can be utilized by language models (LLMs) within agent workflows\n",
    "\n",
    "- LangChain automatically:\n",
    "  - **Assigns a name**: By default, it uses the function's name, but you can specify a custom name\n",
    "  - **Generates a description**: It uses the function's docstring to describe the tool's purpose\n",
    "  - **Infers the input schema**: It analyzes the function's parameters and type annotations to determine the expected inputs\n",
    "\n",
    "- In this example:\n",
    "  - **Name**: add_numbers\n",
    "  - **Description**: \"Add two numbers and return the result.\"\n",
    "  - **Arguments**: a and b, both integers\n",
    "  - The LLM can now call add_numbers as a tool when it determines that adding two numbers is necessary to fulfill a user's request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1719a53",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "<u>**Pay Attention to the Error**</u>\n",
    "\n",
    "<pre> ```ValueError: Function must have a docstring if description not provided. ``` </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a629ec",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Build an Agent With the Tool</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24273e81",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<u>**PAY ATTENTION !!!**</u>\n",
    "<br>\n",
    "The order in the **PROMPT TEMPLATE** matter:\n",
    "- `system`\n",
    "- `MessagesPlaceholder(variable_name=\"agent_scratchpad\")`\n",
    "- `user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [add_numbers]\n",
    "\n",
    "\n",
    "\n",
    "# Create prompt for the agent (optional for custom role)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools when needed.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# Build agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "\n",
    "# Create an executor (to run the agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "\n",
    "\n",
    "# print\n",
    "response = agent_executor.invoke({\"input\": \"What is 7 plus 15?\"})\n",
    "print(response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db717a1",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Adding **verbose=True**</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25ea57",
   "metadata": {},
   "source": [
    "`agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)`\n",
    "<br>\n",
    "\n",
    "- Enables detailed logging of the agent's internal operations\n",
    "- This includes printing intermediate steps, such as the agent's thoughts, actions, and observations, to the console\n",
    "- It's particularly useful for debugging and understanding how the agent processes inputs and utilizes tools\n",
    "- **You can inspect the reasoning/steps by setting `verbose=True` on the executor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3fa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [add_numbers]\n",
    "\n",
    "\n",
    "\n",
    "# Create prompt for the agent (optional for custom role)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools when needed.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# Build agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "\n",
    "# Create an executor (to run the agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# print\n",
    "response = agent_executor.invoke({\"input\": \"What is 7 plus 15?\"})\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Agent Response')\n",
    "print(len('Agent Response')*'-')\n",
    "print(response[\"output\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c26c2d",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98300587",
   "metadata": {},
   "source": [
    "## Example 2: Multi-Tool Agent (Calculator & Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a46045",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Define a Second Tool</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e22f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_country_capital(country: str) -> str:\n",
    "    \"\"\"Return the capital city of a given country.\"\"\"\n",
    "    capitals = {\n",
    "        \"France\": \"Paris\",\n",
    "        \"Israel\": \"Jerusalem\",\n",
    "        \"USA\": \"Washington, D.C.\"\n",
    "    }\n",
    "    return capitals.get(country, \"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4907b1",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Agent With Multiple Tools</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d12e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [add_numbers, get_country_capital]\n",
    "\n",
    "\n",
    "\n",
    "# Create prompt for the agent (optional for custom role)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools when needed.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# Build agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "\n",
    "# Create an executor (to run the agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Ask it a question that could use a tool\n",
    "response = agent_executor.invoke({\"input\": \"What is the capital of France and what is 3 + 4?\"})\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Agent Response')\n",
    "print(len('Agent Response')*'-')\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdeba55",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Agent With Multiple Tools - with a query that <b>doesn't require the tools</b></u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [add_numbers, get_country_capital]\n",
    "\n",
    "\n",
    "\n",
    "# Create prompt for the agent (optional for custom role)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools when needed.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# Build agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "\n",
    "# Create an executor (to run the agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Ask it a question that could use a tool\n",
    "response = agent_executor.invoke({\"input\": \"Tell a short joke\"})\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Agent Response')\n",
    "print(len('Agent Response')*'-')\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b82cb9d",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Agent Flow</b></u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c9a0b",
   "metadata": {},
   "source": [
    "- Agents decide when to call a tool vs. answer directly\n",
    "\n",
    "- If user asks “what is 3 + 4?” → agent will use the calculator tool\n",
    "\n",
    "- If user asks “Tell me a joke” → agent will just use the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abfc0c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f6832",
   "metadata": {},
   "source": [
    "## Example 3: Agent Chaining: Using Outputs From One Tool In Another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a612a3f",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Define the Tools</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b876e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int) -> int:\n",
    "    \"\"\"Multiply a number by 2.\"\"\"\n",
    "    return a * 2\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d049cb",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Agent With Multiple Tools</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [multiply, add]\n",
    "\n",
    "\n",
    "\n",
    "# Create prompt for the agent (optional for custom role)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that can use tools when needed.\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "# Build agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "\n",
    "# Create an executor (to run the agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Ask it a question that could use a tool\n",
    "response = agent_executor.invoke({\"input\": \"If I add 3 and 4, then double it, what do I get?\"})\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Agent Response')\n",
    "print(len('Agent Response')*'-')\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b008f8",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b3a23",
   "metadata": {},
   "source": [
    "## Example 4: Agent With “Session” Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e20e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4e18a",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Define the Tools</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers and return the result.\"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5fa39",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Agent With Memory</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb31837",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<u>**PAY ATTENTION !!!**</u>\n",
    "<br>\n",
    "The order in the **PROMPT TEMPLATE** matter:\n",
    "- `system`\n",
    "- `MessagesPlaceholder(variable_name=\"history\")`\n",
    "- `MessagesPlaceholder(variable_name=\"agent_scratchpad\")`\n",
    "- `user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [add_numbers]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create prompt for the agent (optional for custom role)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant who remembers prior conversation.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an executor (to run the agent)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Wrap with message history for memory\n",
    "store = {}\n",
    "\n",
    "def get_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "\n",
    "chat_agent = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history=get_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "session_id = \"student\"\n",
    "chat_agent.invoke({\"input\": \"Add 5 and 7\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "output = chat_agent.invoke({\"input\": \"What was my last question?\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Agent Response')\n",
    "print(len('Agent Response')*'-')\n",
    "print(output[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6052af",
   "metadata": {},
   "outputs": [],
   "source": [
    "store['student'].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840eac",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b66246",
   "metadata": {},
   "source": [
    "## Example 5: Multi-Agent Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e5e208",
   "metadata": {},
   "source": [
    "- Multi-agent orchestration is an advanced workflow design pattern where several specialized agents—each with their own prompt, role, tools, and potentially memory—collaborate to solve complex tasks\n",
    "- Instead of relying on a single all-knowing agent, you coordinate several agents that can communicate, delegate, and share information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19289a5c",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "### <u>Goal</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a237b",
   "metadata": {},
   "source": [
    "- **Have a \"main agent\" handle user conversation**\n",
    "- If the user asks to \"schedule an appointment,\" the main agent sends the full conversation to an \"advisor agent\"\n",
    "- The advisor extracts the desired date, then suggests 3 appointment options\n",
    "- The advisor will use a custom function for the 3 suggested appointment options\n",
    "- **In this example only the \"main agent\" has memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "#Creating the function\n",
    "@tool\n",
    "def get_next_three_dates(start_date):\n",
    "    'This fuction recieves a date and then return 3 optional dates'\n",
    "    # start_date should be a string in the format 'YYYY-MM-DD'\n",
    "    date_obj = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    return [\n",
    "        (date_obj + timedelta(days=3)).strftime(\"%Y-%m-%d\"),\n",
    "        (date_obj + timedelta(days=6)).strftime(\"%Y-%m-%d\"),\n",
    "        (date_obj + timedelta(days=9)).strftime(\"%Y-%m-%d\"),\n",
    "    ]\n",
    "\n",
    "# Example usage:\n",
    "# print(get_next_three_dates('2024-05-27'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f65a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools\n",
    "tools = [get_next_three_dates]\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-11-20\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main agent: Handles chat and decides when to call advisor\n",
    "main_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are an assistant in a company. If the user wants to schedule an appointment, respond: \"\n",
    "     \"'I will check available slots for you.' Otherwise, answer normally.\"),\n",
    "     MessagesPlaceholder(variable_name=\"history\"),\n",
    "     MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "main_agent = create_openai_tools_agent(llm, tools=[], prompt=main_prompt)\n",
    "main_executor = AgentExecutor(agent=main_agent, tools=[], verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "# Memory store for user sessions\n",
    "store = {}\n",
    "def get_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap the main agent executor with memory\n",
    "main_agent_with_memory = RunnableWithMessageHistory(\n",
    "    main_executor,\n",
    "    get_session_history=get_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Advisor agent: Receives the conversation, extracts the desired date, and suggests slots\n",
    "advisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are an appointment advisor. Extract any preferred dates from the full conversation. \"\n",
    "     \"Then, suggest 3 possible appointment slots for the user, in this format:\\n\"\n",
    "     \"- Option 1: ...\\n- Option 2: ...\\n- Option 3: ...\\n\"\n",
    "     \"You can use the tools provided\"\n",
    "     \"If no date is found, suggest generic options for next week.\"),\n",
    "     MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "advisor_agent = create_openai_tools_agent(llm, tools, prompt=advisor_prompt)\n",
    "advisor_executor = AgentExecutor(agent=advisor_agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c44530",
   "metadata": {},
   "source": [
    "<u>**Orchestration**:</u>\n",
    "- A Python-driven control layer that determines when and how agents interact with each other and with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrate_conversation_with_memory(user_input, session_id=\"user1\"):\n",
    "    \"\"\"\n",
    "    Handles one turn of user input for the main agent (with memory),\n",
    "    and if needed, passes the full memory/history to the advisor agent.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Main agent receives latest user message (memory auto-injects context)\n",
    "    main_output = main_agent_with_memory.invoke({\"input\": user_input},config={\"configurable\": {\"session_id\": session_id}})[\"output\"]\n",
    "    print(\"Main Agent:\", main_output)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # If scheduling is detected, advisor gets *full conversation* from memory\n",
    "    if \"I will check available slots for you\" in main_output:\n",
    "        \n",
    "        # Retrieve full history from memory\n",
    "        full_history = store[session_id].messages\n",
    "        full_convo = \"\\n\".join([f\"{m.type.capitalize()}: {m.content}\" for m in full_history])\n",
    "        \n",
    "        advisor_response = advisor_executor.invoke({\"input\": full_convo})[\"output\"]\n",
    "        print(\"\\n\\n\")\n",
    "        print(\"Advisor Agent:\\n\", advisor_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89715db",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"user77\"\n",
    "# Turn 1\n",
    "orchestrate_conversation_with_memory(\"Hi! I want to learn about your company.\", session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"user77\"\n",
    "# Turn 2\n",
    "orchestrate_conversation_with_memory(\"I'd like to schedule an appointment on 2024-09-02.\", session_id=session_id)\n",
    "# ...keep calling per turn as needed..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67211a",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<u>**Benefit of using Multi-Agent Orchestration**</u>\n",
    "\n",
    "- **Separation of Concerns**: Each agent can focus on its domain (e.g., scheduling, knowledge retrieval, sales)\n",
    "\n",
    "- **Composability**: Easily add, remove, or swap agents without redesigning the whole workflow\n",
    "\n",
    "- **Dynamic Collaboration**: Agents can pass information, escalate issues, or request advice from other agents\n",
    "\n",
    "- **Scalability**: Break down large business processes into modular, maintainable components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f56d5",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<hr class=\"dotted\">\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1645d",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e9ad8",
   "metadata": {},
   "source": [
    "- All custom tools must be decorated with `@tool` and include docstrings for best results\n",
    "\n",
    "- Agents support function calling, so the LLM knows how/when to use each tool\n",
    "\n",
    "- **For production, limit which tools the agent can access and sanitize tool inputs**\n",
    "\n",
    "- Agents + memory enable stateful, contextual workflows\n",
    "\n",
    "- Multi-agent orchestration lets you build robust, scalable, and maintainable LLM-powered systems where agents collaborate like human teams—each focusing on what they do best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
